model_path: meta-llama/Llama-2-7b-hf
dataset: wikitext2
wbits: 4
group_size: 128
save_path: output/llama-2-7b-GPTQ-4bit-g128
act_order: true
CUDA_VISIBLE_DEVICES: "0"